{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c4511b7",
   "metadata": {},
   "source": [
    "# 25-26: 4369 -- PROGRAMMING FOR DATA ANALYTICS\n",
    "## Big Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f8320d",
   "metadata": {},
   "source": [
    "One of the main challenges of this project (I found) was deciding on a suitable data subject to research and then attempting to **source** data.  \n",
    "While I looked into data for Retail Sales, Traffic Accidents, Weather, etc (and browsing Kaggle for potential subjects) ... after several failed attempts, I found that *I needed a pursue a subject I was genuinely curious about.*  \n",
    "\n",
    "I decided to look into the subject of **Trends in the use of Programming Languages** and to leverage the huge data repository of **GitHub** as a data source.  \n",
    "  \n",
    "I wanted to look at Programming Language Trends\n",
    "* Analyze which languages are growing/declining over time\n",
    "* Compare language popularity across different types of projects\n",
    "* Visualize the shift from older to newer languages\n",
    "\n",
    "\n",
    "GitHub Data Sources are available in :  \n",
    "* GitHub API - Free tier allows decent access  \n",
    "* GH Archive - Historical GitHub event data (billions of events!)  \n",
    "* GitHub's public datasets on Google BigQuery  \n",
    "* Pre-made datasets on Kaggle  \n",
    "\n",
    "I looked into the GitHub API as a mechanism to extract the datasets I would require."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b3026e",
   "metadata": {},
   "source": [
    "***\n",
    "## The GitHub REST API with Python\n",
    "### (... and its limitations ðŸ˜–)\n",
    "\n",
    "I experimented a while with Python scripts that collect GitHub Metadata and save to CSV files.  \n",
    "https://blog.apify.com/python-github-api/  \n",
    "https://melaniesoek0120.medium.com/how-to-use-github-api-to-extract-data-with-python-bdc61106a501  \n",
    "\n",
    "I also investigated the use of the PyGithub Library.   \n",
    "https://github.com/PyGithub/PyGithub  \n",
    "https://pygithub.readthedocs.io/en/latest/introduction.html  \n",
    "https://stackoverflow.com/questions/10625190/most-suitable-python-library-for-github-api-v3  \n",
    "https://www.youtube.com/watch?v=QaURSdmP0o8  \n",
    "\n",
    "But, this only highlighted how restrictive this API's \"Rate Limit\" can be.  \n",
    "Look at script below (generated with help of Claude AI) that uses pyGithub module to attempt to look at the count of language specific  repositories created with a specific period  \n",
    "\n",
    "[My Python Script for Extracting Github Data](./testing/github_api_test.py)  \n",
    "Note: To use the PyGithub Module you will need to install PyGithub library with  \n",
    "`pip install PyGithub`  \n",
    "\n",
    "If you look at the results of this script (output to [this text file](./testing/Github_REST_API_Results.txt)), all language for all months return exactly same result ... \"1,000 repos\"  \n",
    "**I am obviously hitting a limit of some sort here.**\n",
    "   \n",
    "A simplified version (with a hard-coded sample) is shown below where a reduced time interval of only 3 hours is used...   \n",
    "It still returns a count close to the limit of 1000 repositories   \n",
    "\n",
    "*Experimentation with values for language, start_date, and end_date highlight how restrictive this 1000 limit is.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "555e1408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated as: ngn73\n",
      "Count of Python repos created between 2024-03-01T00:00:00+00:00 and 2024-03-01T03:00:00+00:00: 940\n"
     ]
    }
   ],
   "source": [
    "from github import Github, RateLimitExceededException, Auth\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the token from environment variables\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "\n",
    "# Create authentication object\n",
    "auth = Auth.Token(GITHUB_TOKEN)\n",
    "# Initialize GitHub client with auth\n",
    "g = Github(auth=auth)\n",
    "\n",
    "# Verify authentication\n",
    "try:\n",
    "    user = g.get_user()\n",
    "    print(f\"Authenticated as: {user.login}\")\n",
    "except Exception as e:\n",
    "    print(f\"Authentication failed: {e}\")\n",
    "\n",
    "# Example usage \n",
    "language = 'Python'\n",
    "start_date = '2024-03-01T00:00:00+00:00'\n",
    "end_date = '2024-03-01T03:00:00+00:00'\n",
    "\n",
    "# Build the API search query\n",
    "query = f\"language:{language} created:{start_date}..{end_date}\"\n",
    "# Search repositories with PyGithub\n",
    "result = g.search_repositories(query=query)\n",
    "# Get total count\n",
    "total_count = result.totalCount\n",
    "print(f\"Count of {language} repos created between {start_date} and {end_date}: {total_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa94ae",
   "metadata": {},
   "source": [
    "<font color=\"crimson\">... **I needed to find an alternative (less restrictive) method to extracting Github Repository metadata.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483bc969",
   "metadata": {},
   "source": [
    "***\n",
    "## Google BigQuery + GitHub Archive  \n",
    "  \n",
    "https://console.cloud.google.com/  \n",
    "\n",
    "Google is in collaboration with GitHub to release an incredible new open dataset on **Google BigQuery**  \n",
    "The Google BigQuery Public Datasets program now offers a full snapshot of the content of more than 2.8 million open source GitHub repositories in BigQuery  \n",
    "This provides a alternative mechanism to analyze the source code of almost 2 billion files with a simple (or complex) SQL query.   \n",
    "  \n",
    "\n",
    "https://cloud.google.com/blog/topics/public-datasets/github-on-bigquery-analyze-all-the-open-source-code  \n",
    "https://hoffa.medium.com/github-on-bigquery-analyze-all-the-code-b3576fd2b150  \n",
    "https://hoffa.medium.com/400-000-github-repositories-1-billion-files-14-terabytes-of-code-spaces-or-tabs-7cfe0b5dd7fd  \n",
    "https://github.com/fhoffa/analyzing_github?tab=readme-ov-file  \n",
    "\n",
    "The use of SQL is ideal as I am quite comfortable with the SQL syntax  \n",
    "https://docs.cloud.google.com/bigquery/docs/reference/rest?apix=true   \n",
    "\n",
    "<img src=\"../images/Goole_BigQuery_SQL.png\" alt=\"Google BigQuery\" width=\"600\">\n",
    "\n",
    "**These SQL scripts can be used to format/configure Datasets as required by the needs of my Data Analysis   \n",
    "Results can then be saved as CSV or JSon files for further processing with Python.**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259bfdd0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
