{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c4511b7",
   "metadata": {},
   "source": [
    "# 25-26: 4369 -- PROGRAMMING FOR DATA ANALYTICS\n",
    "## Big Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f8320d",
   "metadata": {},
   "source": [
    "One of the main challenges of this project (I found) was deciding on a suitable data subject to research and then attempting to **source** data.  \n",
    "While I looked into data for Retail Sales, Traffic Accidents, Weather, etc (and browsing Kaggle for potential subjects) ... after several failed attempts, I found that *I needed a pursue a subject I was genuinely curious about.*  \n",
    "\n",
    "I decided to look into the subject of **Trends in the use of Programming Languages** and to leverage the huge data repository of **GitHub** as a data source.  \n",
    "  \n",
    "I wanted to look at Programming Language Trends\n",
    "* Analyze which languages are growing/declining over time\n",
    "* Compare language popularity across different types of projects\n",
    "* Visualize the shift from older to newer languages\n",
    "\n",
    "\n",
    "GitHub Data Sources are available in :  \n",
    "* GitHub API - Free tier allows decent access  \n",
    "* GH Archive - Historical GitHub event data (billions of events!)  \n",
    "* GitHub's public datasets on Google BigQuery  \n",
    "* Pre-made datasets on Kaggle  \n",
    "\n",
    "I initially looked into the GitHub API as a mechanism to extract the datasets I would require."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b3026e",
   "metadata": {},
   "source": [
    "***\n",
    "## The GitHub REST API with Python\n",
    "### (... and its limitations ðŸ˜–)\n",
    "\n",
    "I experimented a while with Python scripts that collect GitHub Metadata and save to CSV files.  \n",
    "https://blog.apify.com/python-github-api/  \n",
    "https://melaniesoek0120.medium.com/how-to-use-github-api-to-extract-data-with-python-bdc61106a501  \n",
    "\n",
    "I also investigated the use of the PyGithub Library.   \n",
    "https://github.com/PyGithub/PyGithub  \n",
    "https://pygithub.readthedocs.io/en/latest/introduction.html  \n",
    "https://stackoverflow.com/questions/10625190/most-suitable-python-library-for-github-api-v3  \n",
    "https://www.youtube.com/watch?v=QaURSdmP0o8  \n",
    "\n",
    "But, this only highlighted how restrictive this API's \"Rate Limit\" can be.  \n",
    "Look at script below (generated with help of Claude AI) that uses pyGithub module to attempt to look at the count of language specific  repositories created with a specific period  \n",
    "\n",
    "[My Python Script for Extracting Github Data](./testing/github_api_test.py)  \n",
    "Note: To use the PyGithub Module you will need to install PyGithub library with  \n",
    "`pip install PyGithub`  \n",
    "\n",
    "If you look at the results of this script (output to [this text file](./testing/Github_REST_API_Results.txt)), all language for all months return exactly same result ... \"1,000 repos\"  \n",
    "**I am obviously hitting a limit of some sort here.**\n",
    "   \n",
    "A simplified version (with a hard-coded sample) is shown below where a reduced time interval of only 3 hours is used...   \n",
    "It still returns a count close to the limit of 1000 repositories   \n",
    "\n",
    "*Experimentation with values for language, start_date, and end_date highlight how restrictive this 1000 limit is.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "555e1408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated as: ngn73\n",
      "Count of Python repos created between 2024-03-01T00:00:00+00:00 and 2024-03-01T03:00:00+00:00: 940\n"
     ]
    }
   ],
   "source": [
    "from github import Github, RateLimitExceededException, Auth\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the token from environment variables\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "\n",
    "# Create authentication object\n",
    "auth = Auth.Token(GITHUB_TOKEN)\n",
    "# Initialize GitHub client with auth\n",
    "g = Github(auth=auth)\n",
    "\n",
    "# Verify authentication\n",
    "try:\n",
    "    user = g.get_user()\n",
    "    print(f\"Authenticated as: {user.login}\")\n",
    "except Exception as e:\n",
    "    print(f\"Authentication failed: {e}\")\n",
    "\n",
    "# Example usage \n",
    "language = 'Python'\n",
    "start_date = '2024-03-01T00:00:00+00:00'\n",
    "end_date = '2024-03-01T03:00:00+00:00'\n",
    "\n",
    "# Build the API search query\n",
    "query = f\"language:{language} created:{start_date}..{end_date}\"\n",
    "# Search repositories with PyGithub\n",
    "result = g.search_repositories(query=query)\n",
    "# Get total count\n",
    "total_count = result.totalCount\n",
    "print(f\"Count of {language} repos created between {start_date} and {end_date}: {total_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa94ae",
   "metadata": {},
   "source": [
    "<font color=\"crimson\">... **I needed to find an alternative (less restrictive) method to extracting Github Repository metadata.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483bc969",
   "metadata": {},
   "source": [
    "***\n",
    "## Google BigQuery + GitHub Archive  \n",
    "  \n",
    "https://console.cloud.google.com/bigquery/  \n",
    "\n",
    "\n",
    "Google is in collaboration with GitHub to release an incredible new open dataset on **Google BigQuery**  \n",
    "The Google BigQuery Public Datasets program now offers a full snapshot of the content of more than 2.8 million open source GitHub repositories in BigQuery  \n",
    "This provides a alternative mechanism to analyze the source code of almost 2 billion files with a simple (or complex) SQL query.   \n",
    "  \n",
    "\n",
    "https://cloud.google.com/blog/topics/public-datasets/github-on-bigquery-analyze-all-the-open-source-code  \n",
    "https://hoffa.medium.com/github-on-bigquery-analyze-all-the-code-b3576fd2b150  \n",
    "https://hoffa.medium.com/400-000-github-repositories-1-billion-files-14-terabytes-of-code-spaces-or-tabs-7cfe0b5dd7fd  \n",
    "https://github.com/fhoffa/analyzing_github?tab=readme-ov-file  \n",
    "\n",
    "The use of SQL is ideal as I am quite comfortable with the SQL syntax  \n",
    "https://docs.cloud.google.com/bigquery/docs/reference/rest?apix=true   \n",
    "https://codelabs.developers.google.com/codelabs/bigquery-github#0  \n",
    "\n",
    "There is a lot of menus within Google Cloud. Within Google Cloud, goto Navigation Menu -> BigQuery->Studio and select 'SQL Query'\n",
    "<img src=\"../images/Goole_BigQuery_SQL.png\" alt=\"Google BigQuery\" width=\"600\">  \n",
    "\n",
    "**These SQL scripts can be used to format/configure Datasets as required by the needs of my Data Analysis   \n",
    "Results can then be saved as CSV or JSon files for further processing with Python.**  \n",
    "  \n",
    "The core tables to query against have the following sample names:\n",
    "\n",
    "* **githubarchive.day.20241201** (Archive for December 1, 2024)  \n",
    "* **githubarchive.day.20241130** (Archive for November 30, 2024)  \n",
    "* **githubarchive.day.20241129** (Archive for November 29, 2024)  \n",
    "  \n",
    "The format is: `githubarchive.day.YYMMDD`   \n",
    "To query the whole of 2024 you can use a wildcard in the Table name (e.g. githubarchive.day.2024*)  \n",
    "\n",
    "\n",
    "\n",
    "The details of each Gitub event (push, pull, create, frk, etc.) are stored within the \"payload\" field. The content of the \"payload\" field is different for each event type and may be updated by GitHub at any point, hence it is kept as a serialized JSON string value in BigQuery. JSON_EXTRACT functions can be used to apply filters to this Field  \n",
    "  \n",
    "https://www.gharchive.org/#:~:text=The%20content%20of%20the%20%22payload,access%20data%20in%20this%20field.  \n",
    "https://github.com/igrigorik/gharchive.org/issues/148  \n",
    "  \n",
    "  \n",
    "An example SQL script below filters 'pull' events for Python and Javascript languages using **JSON_EXTRACT_SCALAR( )**\n",
    "\n",
    "```\n",
    "SELECT \n",
    "    FORMAT_DATE('%Y-%m', PARSE_DATE('%y%m%d', _TABLE_SUFFIX)) as month,\n",
    "    JSON_EXTRACT_SCALAR(payload, '$.pull_request.base.repo.language') as language,\n",
    "    COUNT(*) as pr_count,\n",
    "    COUNT(DISTINCT repo.name) as active_repos\n",
    "FROM `githubarchive.day.20*`\n",
    "WHERE \n",
    "    type = 'PullRequestEvent'\n",
    "    AND JSON_EXTRACT_SCALAR(payload, '$.pull_request.base.repo.language') IN ('Python', 'JavaScript')\n",
    "    AND _TABLE_SUFFIX BETWEEN \n",
    "        FORMAT_DATE('%y%m%d', DATE_SUB(CURRENT_DATE(), INTERVAL 6 MONTH))\n",
    "        AND FORMAT_DATE('%y%m%d', CURRENT_DATE())\n",
    "GROUP BY month, language\n",
    "ORDER BY month DESC, pr_count DESC;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259bfdd0",
   "metadata": {},
   "source": [
    "***\n",
    "## Using BigQuery and Python\n",
    "Python can integrate with BigQuery Datasources with the **google-cloud-bigquery** package.  \n",
    "https://docs.cloud.google.com/python/docs/reference/bigquery/latest  \n",
    "This will require the Setup of authentication that will require additional configuration (application credentials, project_id, etc.).  \n",
    "But, in the interests of migrating code other machines (and allowing code to be potentially tested by Andrew), I would definitely be better off using the BigQuery console directly for simpler, manual exports of SQL Data Resultsets (into CSV or JSon format)  \n",
    "  \n",
    "**So I will use the BigQuery console directly to generate CSV or JSon result Files that will act as the Data-source for Analysis Project.**\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
